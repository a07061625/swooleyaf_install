input {
  redis {
    batch_count => 1
    data_type => "list"
    key => "sla00_00002"
    host => "127.0.0.1"
    port => 6688
    password => "yjbn15su"
    db => 2
    threads => 1
  }
}

filter {
  grok {
    match => ["message", "(?<logdate>\d{4}/\d{2}/\d{2}\s{1,}\d{2}:\d{2}:\d{2})"]
  }
  date {
    locale => "en"
    match => ["logdate", "yyyy/MM/dd HH:mm:ss"]
  }
  mutate {
    remove_field => ["logdate", "redis_key", "log"]
  }
  ruby {
    code => "event.set('create_time',(event.get('@timestamp').to_f.round(3)*1000).to_i)"
  }
}

output {
  # 选择下面其中一个即可
  redis {
    batch => true
    batch_timeout => 3
    data_type => "list"
    host => ["127.0.0.1:6688"]
    password => "yjbn15su"
    db => 2
    key => "sla01_00001"
    codec => "json"
    timeout => 5
    workers => 1
  }
  elasticsearch {
    hosts => "192.168.96.21:9201"
    index => "log-%{+YYYY-MM-dd}"
    user => "elastic"
    password => "jw07061625"
  }
  clickhouse {
    headers => ["Authorization", "Basic YWRtaW46cGFzc3dvcmQxMjM="]
    http_hosts => ["http://127.0.0.1:8123/"]
    table => "default.table"
    request_tolerance => 1 //发生重试前,响应状态码非200的请求次数
    #automatic_retries => 1 //每个host的重试次数
    #backoff_time => 3 //每次重试之间的间隔时间,单位为秒
    #flush_size => 50 //每次提交的数据量
    #idle_flush_time => 5 //每次提交的最大等待时间,单位为秒
  }
}
